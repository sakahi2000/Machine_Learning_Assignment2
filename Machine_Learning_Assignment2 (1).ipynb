{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assignment Code: DA-AG-011\n",
        "Name: Sakshi Upadhyay\n",
        "Email: sakshiup74744@gmail.com\n",
        "\n",
        "\n",
        "Q1. What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "\n",
        "Ans. Logistic regression is a technique used when you want to predict categories, like whether an email is spam or not, or whether someone will buy a product — basically a yes or no kind of outcome.\n",
        "On the other hand, linear regression is used when you want to predict numbers, like the price of a house, someone's salary, or the temperature tomorrow.\n",
        "Linear regression draws a straight line to predict values. You give it some input (like years of experience), and it tells you a number (like expected salary).\n",
        "Logistic regression doesn't give a number like 72 or 5.4 — it gives a probability (like 0.8), which means \"80% chance this is spam.\" Then it converts that into a category (like spam or not spam).\n",
        "\n",
        "\n",
        "Q.2  Explain the role of the Sigmoid function in Logistic Regression ?\n",
        "Ans.In logistic regression, the sigmoid function is what helps the model make decisions in terms of probabilities.\n",
        "Logistic regression first does what linear regression does — it takes your inputs (like age, salary, etc.), multiplies them by some weights, adds them up, and gets a number. This number could be anything — negative, positive, small, or large.\n",
        "But we don’t want just any number — we want something between 0 and 1, because we’re trying to say how likely something is. That’s where the sigmoid function comes in.\n",
        "\n",
        "Q3. What is Regularization in Logistic Regression and why is it needed ?\n",
        "Ans. Regularization is like adding a rule to keep your logistic regression model from going overboard.\n",
        "Imagine you're training a model to predict whether someone will buy a product based on their age, income, location, etc. Now, if your model gets too focused on tiny quirks or noise in the data, it might start giving too much importance to certain features — even if they aren’t that useful. This is called overfitting.\n",
        "Regularization helps prevent this by penalizing the model for being too complex.\n",
        "Because logistic regression is a linear model, if you have a lot of features or if they’re noisy, it might try too hard to fit everything perfectly. That leads to a model that performs well on training data but poorly on new, unseen data — which we don’t want.\n",
        "\n",
        "Q4. What are some common evaluation metrics for classification models, and why are they important?\n",
        "Ans. Classification models are evaluated using several metrics to measure their performance. Some of the most commonly used metrics are:\n",
        "\n",
        "Accuracy:\n",
        "\n",
        "Definition: The ratio of correctly predicted instances to the total number of instances.\n",
        "\n",
        "Importance: Gives an overall idea of how well the model is performing.\n",
        "\n",
        "Limitation: Not reliable when the data is imbalanced.\n",
        "\n",
        "Precision:\n",
        "\n",
        "Definition: The ratio of true positives to the total predicted positives.\n",
        "\n",
        "Formula: Precision = TP / (TP + FP)\n",
        "\n",
        "Importance: Indicates how many of the predicted positive instances are actually correct.\n",
        "\n",
        "Useful when false positives are costly.\n",
        "\n",
        "Recall (Sensitivity or True Positive Rate):\n",
        "\n",
        "Definition: The ratio of true positives to the total actual positives.\n",
        "\n",
        "Formula: Recall = TP / (TP + FN)\n",
        "\n",
        "Importance: Measures how well the model identifies actual positive cases.\n",
        "\n",
        "Useful when false negatives are critical (e.g., in medical diagnoses).\n",
        "\n",
        "F1 Score:\n",
        "\n",
        "Definition: The harmonic mean of precision and recall.\n",
        "\n",
        "Formula: F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
        "\n",
        "Importance: Balances precision and recall; useful when both are equally important.\n",
        "\n",
        "ROC-AUC (Receiver Operating Characteristic – Area Under Curve):\n",
        "\n",
        "Definition: Measures the model's ability to distinguish between classes.\n",
        "\n",
        "Importance: Provides a comprehensive view of performance across all classification thresholds.\n",
        "\n",
        "AUC closer to 1 indicates a better performing model.\n",
        "\n",
        "\n",
        "Q.5 Write a Python program that loads a CSV file into a Pandas DataFrame, splits into train/test sets, trains a Logistic Regression model, and prints its accuracy. (Use Dataset from sklearn package)"
      ],
      "metadata": {
        "id": "zT41ys4gHgEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=10000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of Logistic Regression model:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knrGaw-gHnNY",
        "outputId": "5b46bbf6-eeac-4e19-b974-da9d952aaf6e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Logistic Regression model: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.\n"
      ],
      "metadata": {
        "id": "FUEZyo4nHwzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear')  # L2 regularization\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Model Coefficients:\")\n",
        "print(model.coef_)\n",
        "print(\"\\nIntercept:\")\n",
        "print(model.intercept_)\n",
        "print(\"\\nAccuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFq6AOt8IGgf",
        "outputId": "8a502b56-ff21-4d38-e189-6847ba27f323"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients:\n",
            "[[ 2.13248406e+00  1.52771940e-01 -1.45091255e-01 -8.28669349e-04\n",
            "  -1.42636015e-01 -4.15568847e-01 -6.51940282e-01 -3.44456106e-01\n",
            "  -2.07613380e-01 -2.97739324e-02 -5.00338038e-02  1.44298427e+00\n",
            "  -3.03857384e-01 -7.25692126e-02 -1.61591524e-02 -1.90655332e-03\n",
            "  -4.48855442e-02 -3.77188737e-02 -4.17516190e-02  5.61347410e-03\n",
            "   1.23214996e+00 -4.04581097e-01 -3.62091502e-02 -2.70867580e-02\n",
            "  -2.62630530e-01 -1.20898539e+00 -1.61796947e+00 -6.15250835e-01\n",
            "  -7.42763610e-01 -1.16960181e-01]]\n",
            "\n",
            "Intercept:\n",
            "[0.40847797]\n",
            "\n",
            "Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report. (Use Dataset from sklearn package)"
      ],
      "metadata": {
        "id": "SzzAfeyxIQQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zts9JsmTIdt6",
        "outputId": "0837e425-369d-420b-be5d-f7444c46ee62"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.8 Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation accuracy.\n"
      ],
      "metadata": {
        "id": "LCMx9S1II3en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(LogisticRegression(multi_class='ovr'), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "dPyMLVN8I3Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.9 Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling.\n",
        "(Use Dataset from sklearn package)\n",
        "(Include your Python code and output in the code box below.)\n"
      ],
      "metadata": {
        "id": "uiNIuz5AJhKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression without scaling\n",
        "model_no_scaling = LogisticRegression(max_iter=10000)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "acc_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Logistic Regression with scaling\n",
        "model_scaled = LogisticRegression(max_iter=10000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Print the comparison\n",
        "print(\"Accuracy without scaling:\", acc_no_scaling)\n",
        "print(\"Accuracy with scaling:\", acc_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSjY2r5OJm--",
        "outputId": "5bb82dec-e2d1-423d-b2c4-c3986fc011a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.956140350877193\n",
            "Accuracy with scaling: 0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.10  Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.\n",
        "\n",
        "Ans. To build a Logistic Regression model for predicting customer responses in an imbalanced dataset scenario (5% positive class), the following systematic approach should be taken:\n",
        "\n",
        "1. Data Handling\n",
        "Load and explore the dataset to understand the features and target variable.\n",
        "\n",
        "Handle missing values, outliers, and incorrect data types.\n",
        "\n",
        "Perform feature engineering to create meaningful variables (e.g., total purchases, time since last activity).\n",
        "\n",
        "Encode categorical variables using label encoding or one-hot encoding.\n",
        "\n",
        "2. Feature Scaling\n",
        "Use StandardScaler to normalize numerical features.\n",
        "\n",
        "This ensures that all features contribute equally and improves the performance of Logistic Regression, especially when regularization is used.\n",
        "\n",
        "3. Dealing with Class Imbalance\n",
        "Due to only 5% of customers being responders, special handling is required:\n",
        "\n",
        "Class Weighting: Use class_weight='balanced' in Logistic Regression to penalize the majority class more lightly.\n",
        "\n",
        "Oversampling or Undersampling (optional): Apply techniques like SMOTE to balance classes or randomly undersample the majority class.\n",
        "\n",
        "4. Train-Test Split\n",
        "Use train_test_split() with the stratify parameter to maintain the class distribution in both training and testing datasets.\n",
        "\n",
        "5. Hyperparameter Tuning\n",
        "Use GridSearchCV to tune hyperparameters such as:\n",
        "\n",
        "C: Regularization strength\n",
        "\n",
        "penalty: Type of regularization (l1 or l2)\n",
        "\n",
        "solver: Suitable solver (e.g., liblinear for small datasets)\n",
        "\n",
        "6. Model Evaluation\n",
        "Since the data is imbalanced, accuracy is not sufficient. Better evaluation metrics include:\n",
        "\n",
        "Precision: Percentage of predicted responders that are actually correct.\n",
        "\n",
        "Recall: Percentage of actual responders correctly identified.\n",
        "\n",
        "F1-Score: Harmonic mean of precision and recall.\n",
        "\n",
        "ROC-AUC Score: Measures how well the model distinguishes between classes.\n",
        "\n",
        "Confusion Matrix: Provides insight into true/false positives and negatives.\n",
        "\n",
        "Also, threshold tuning may be applied (default is 0.5) to maximize recall or precision depending on business needs.\n",
        "\n",
        "7. Business Application\n",
        "Use predicted probabilities to rank customers by their likelihood to respond.\n",
        "\n",
        "Deploy the model to help marketing teams target only high-probability customers, optimizing campaign costs and improving ROI."
      ],
      "metadata": {
        "id": "dXbRE5FtJwZl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zeF9DNqLJv05"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}